{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "random_state = 123\n",
        "np.random.seed(random_state)\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH']='true'\n",
        "from os.path import abspath, join\n",
        "from os import listdir\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(random_state)\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from PIL import Image, ImageOps"
      ],
      "metadata": {
        "id": "IMPTHwj7pvCK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGcKUJKoYOgw",
        "outputId": "3e6fadc1-2875-40d5-a2d0-c3b41df68769"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Get the absolute path of the current folder\n",
        "# abspath_curr = '/content/drive/My Drive/data'\n"
      ],
      "metadata": {
        "id": "oJX_HakYYOaA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "gkxPNFgXpbIJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base_test_dir = '/content/drive/MyDrive/data/archive/data/test'\n",
        "# test_pos_dir = join(base_test_dir, 'yes')\n",
        "# test_neg_dir = join(base_test_dir, 'no')"
      ],
      "metadata": {
        "id": "6Ld9u4kRpbGC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_pos_imgs = listdir(test_pos_dir)\n",
        "# test_neg_imgs = listdir(test_neg_dir)\n",
        "\n",
        "# n_pos = len(test_pos_imgs)\n",
        "# n_neg = len(test_neg_imgs)\n",
        "# total_test_images = n_pos + n_neg\n",
        "# print(f\"Total images in the dataset: {total_test_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-LxwMZBpbEI",
        "outputId": "af03d99b-06d2-40d8-d183-7ee62a513edc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images in the dataset: 600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base_train_dir = '/content/drive/MyDrive/data/archive/data/train'\n",
        "# train_pos_dir = join(base_train_dir, 'yes')\n",
        "# train_neg_dir = join(base_train_dir, 'no')"
      ],
      "metadata": {
        "id": "t0gz0LgYpbB5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_pos_imgs = listdir(train_pos_dir)\n",
        "# train_neg_imgs = listdir(train_neg_dir)\n",
        "\n",
        "# n_pos = len(train_pos_imgs)\n",
        "# n_neg = len(train_neg_imgs)\n",
        "# total_train_images = n_pos + n_neg\n",
        "# print(f\"Total images in the dataset: {total_train_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sdQVrGUpa_i",
        "outputId": "749a93d9-cdfa-4ab2-ea8e-3ce82c2faae5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images in the dataset: 1800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base_val_dir = '/content/drive/MyDrive/data/archive/data/test'\n",
        "# val_pos_dir = join(base_val_dir, 'yes')\n",
        "# val_neg_dir = join(base_val_dir, 'no')"
      ],
      "metadata": {
        "id": "2Fgxw2WTpa8z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val_pos_imgs = listdir(val_pos_dir)\n",
        "# val_neg_imgs = listdir(val_neg_dir)\n",
        "\n",
        "# n_pos = len(val_pos_imgs)\n",
        "# n_neg = len(val_neg_imgs)\n",
        "# total_val_images = n_pos + n_neg\n",
        "# print(f\"Total images in the dataset: {total_val_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZFTyB2Gpa1B",
        "outputId": "895c3fde-5b47-4f83-bb8d-eb3e0e98df1c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images in the dataset: 600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Pipeline\n",
        "# #batch_size = 32\n",
        "# #img_size = [224, 224]\n",
        "\n",
        "# batch_size = 50\n",
        "# img_size = [256, 256]\n",
        "\n",
        "\n",
        "# base_dir = '/content/drive/MyDrive/data/archive/data'\n",
        "\n",
        "# # Create the training set\n",
        "# train_dir = join(base_dir, 'train')\n",
        "# train_ds = keras.utils.image_dataset_from_directory(train_dir,\n",
        "#                                                     label_mode='binary', class_names = ['yes', 'no'],\n",
        "#                                                     color_mode='grayscale',\n",
        "#                                                     batch_size=batch_size,\n",
        "#                                                     image_size=img_size,\n",
        "#                                                     shuffle=True,\n",
        "#                                                     seed=random_state,\n",
        "#                                                     validation_split=None,\n",
        "#                                                     interpolation='bilinear')\n",
        "\n",
        "\n",
        "# # Create the validation set\n",
        "# val_dir = join(base_dir, 'validation')\n",
        "# val_ds = keras.utils.image_dataset_from_directory(val_dir,\n",
        "#                                                   label_mode='binary', class_names = ['yes', 'no'],\n",
        "#                                                   color_mode='grayscale',\n",
        "#                                                   batch_size=batch_size,\n",
        "#                                                   image_size=img_size,\n",
        "#                                                   shuffle=True,\n",
        "#                                                   seed=random_state,\n",
        "#                                                   validation_split=None,\n",
        "#                                                   interpolation='bilinear')\n",
        "\n",
        "# # Create the test set\n",
        "# test_dir = join(base_dir, 'test')\n",
        "# test_ds = keras.utils.image_dataset_from_directory(test_dir,\n",
        "#                                                    label_mode='binary', class_names = ['yes', 'no'],\n",
        "#                                                    color_mode='grayscale',\n",
        "#                                                    batch_size=batch_size,\n",
        "#                                                    image_size=img_size,\n",
        "#                                                    shuffle=True,\n",
        "#                                                    seed=random_state,\n",
        "#                                                    validation_split=None,\n",
        "#                                                    interpolation='bilinear')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INxwAYfZGFp_",
        "outputId": "3d223197-833e-472d-fddb-5ec1c5f430e2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1800 files belonging to 2 classes.\n",
            "Found 600 files belonging to 2 classes.\n",
            "Found 600 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install Augmentor\n",
        "import Augmentor\n",
        "\n",
        "\n",
        "def img_augment_pipline(img_path):\n",
        "    num = len(os.listdir(img_path))\n",
        "    p = Augmentor.Pipeline(img_path)\n",
        "    p.rotate(probability=1, max_left_rotation=15, max_right_rotation=15)\n",
        "    p.scale(probability=0.5, scale_factor=1.1)\n",
        "    p.random_brightness(probability=1, min_factor=0.8, max_factor=1.2)\n",
        "    p.flip_random(probability=0.9)\n",
        "    p.random_contrast(probability=0.7, min_factor=0.8, max_factor=1.2)\n",
        "    p.flip_random(probability=0.9)\n",
        "    # # skew \n",
        "    # p.skew(probability=0.6, magnitude=0.8)\n",
        "    # # shearing \n",
        "    # p.shear(probability=0.6, max_shear_left=15, max_shear_right=15)\n",
        "    # # random_crop\n",
        "    # p.crop_random(probability=1, percentage_area=0.8, randomise_percentage_area=True)\n",
        "    # random erase\n",
        "    # p.random_erasing(probability=1, rectangle_area=0.5)\n",
        "    # p.sample(num * 2)\n",
        "\n",
        "img_augment_pipline('/content/drive/MyDrive/data/archive/data/train/yes')\n",
        "img_augment_pipline('/content/drive/MyDrive/data/archive/data/train/no')\n",
        "img_augment_pipline('/content/drive/MyDrive/data/archive/data/test/yes')\n",
        "img_augment_pipline('/content/drive/MyDrive/data/archive/data/test/no')\n",
        "img_augment_pipline('/content/drive/MyDrive/data/archive/data/validation/yes')\n",
        "img_augment_pipline('/content/drive/MyDrive/data/archive/data/validation/no')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvyhm4N6zWEV",
        "outputId": "becf8c2e-fb95-487c-e2f1-ec6dbb934481"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Augmentor in /usr/local/lib/python3.8/dist-packages (0.2.10)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from Augmentor) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.8/dist-packages (from Augmentor) (4.64.1)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.8/dist-packages (from Augmentor) (0.16.0)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.8/dist-packages (from Augmentor) (7.1.2)\n",
            "Initialised with 900 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/data/archive/data/train/yes/output.Initialised with 900 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/data/archive/data/train/no/output.Initialised with 300 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/data/archive/data/test/yes/output.Initialised with 300 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/data/archive/data/test/no/output.Initialised with 300 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/data/archive/data/validation/yes/output.Initialised with 300 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/data/archive/data/validation/no/output."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_dir = '/content/drive/MyDrive/data/archive/data/train/yes/output'\n",
        "train_neg_dir = '/content/drive/MyDrive/data/archive/data/train/no/output'\n",
        "test_pos_dir = '/content/drive/MyDrive/data/archive/data/test/yes/output'\n",
        "test_neg_dir = '/content/drive/MyDrive/data/archive/data/test/no/output'\n",
        "val_pos_dir = '/content/drive/MyDrive/data/archive/data/validation/yes/output'\n",
        "val_neg_dir = '/content/drive/MyDrive/data/archive/data/validation/no/output'"
      ],
      "metadata": {
        "id": "M4IwwEQm3pzE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "train_pos_imgs = listdir(train_pos_dir)\n",
        "train_neg_imgs = listdir(train_neg_dir)\n",
        "\n",
        "n_pos_train = len(train_pos_imgs)\n",
        "n_neg_train = len(train_neg_imgs)\n",
        "total_train_images = n_pos_train + n_neg_train\n",
        "print(f\"Total images in the training dataset: {total_train_images}\")\n",
        "#test\n",
        "test_pos_imgs = listdir(test_pos_dir)\n",
        "test_neg_imgs = listdir(test_neg_dir)\n",
        "\n",
        "n_pos_test = len(test_pos_imgs)\n",
        "n_neg_test = len(test_neg_imgs)\n",
        "total_test_images = n_pos_test + n_neg_test\n",
        "print(f\"Total images in the testing dataset: {total_test_images}\")\n",
        "#validation\n",
        "val_pos_imgs = listdir(val_pos_dir)\n",
        "val_neg_imgs = listdir(val_neg_dir)\n",
        "\n",
        "n_pos_val = len(val_pos_imgs)\n",
        "n_neg_val = len(val_neg_imgs)\n",
        "total_val_images = n_pos_val + n_neg_val\n",
        "print(f\"Total images in the validation dataset: {total_val_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPbYiOsX3jiv",
        "outputId": "b5e13baa-a5f8-42df-d195-241243dac5ab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images in the training dataset: 9006\n",
            "Total images in the testing dataset: 1920\n",
            "Total images in the validation dataset: 1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # horizontal flip with probability 1 (default is 0.5)\n",
        "# from torchvision import transforms\n",
        "# # loader_transform = transforms.RandomHorizontalFlip(p=1)\n",
        "\n",
        "\n",
        "# # # brightness\n",
        "# # loader_transform1 = transforms.ColorJitter(brightness=2)\n",
        "\n",
        "# # # contrast\n",
        "# # loader_transform2 = transforms.ColorJitter(contrast=2)\n",
        "\n",
        "# # random flip > bringtness > contrast \n",
        "# # loader_transform = transforms.Compose(\n",
        "# #     transforms.RandomHorizontalFlip(p=1),\n",
        "# #     transforms.RandomRotation(0.5),\n",
        "#     # transforms.RandomContrast(factor=[0, 0.3]))\n",
        "\n",
        "\n",
        "# # resize_and_rescale = keras.Sequential([\n",
        "# #   layers.Resizing(img_size),\n",
        "# #   layers.Rescaling(1./255)\n",
        "# # ])\n",
        "\n",
        "# # data_augmentation = keras.Sequential([\n",
        "# #     RandomFlip(\"horizontal_and_vertical\"),\n",
        "# #   layers.RandomRotation(0.5),\n",
        "# #   layers.RandomContrast(factor=[0, 0.3], seed=random_state)(y2)\n",
        "# # ])\n",
        "\n",
        "# def visualize(original, augmented):\n",
        "#     fig = plt.figure()\n",
        "#     plt.subplot(1,2,1)\n",
        "#     plt.title('Original image')\n",
        "#     plt.imshow(original)\n",
        "#     plt.axis(\"off\")\n",
        " \n",
        "#     plt.subplot(1,2,2)\n",
        "#     plt.title('Augmented image')\n",
        "#     plt.imshow(augmented)\n",
        "#     plt.axis(\"off\")\n",
        "    \n",
        "# for i in range(3):\n",
        "#   seed = (i, 0)  # tuple of size (2,)\n",
        "#   stateless_random_brightness = tf.image.stateless_random_brightness(\n",
        "#       test_ds, max_delta=0.95, seed=seed)\n",
        "#   visualize(test_ds, stateless_random_brightness)\n",
        "\n",
        "# # aug_ds = train_ds.map(lambda x, y: (loader_transform(x, training=True), y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Qp7-BtO-_fCv",
        "outputId": "95c22dfa-841b-4fb4-88b3-3a9301d9bc1a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6ba235c8b5e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# tuple of size (2,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m   stateless_random_brightness = tf.image.stateless_random_brightness(\n\u001b[0m\u001b[1;32m     45\u001b[0m       test_ds, max_delta=0.95, seed=seed)\n\u001b[1;32m     46\u001b[0m   \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstateless_random_brightness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (<BatchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>) to a Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# yes_train=[]\n",
        "# yes_test=[]\n",
        "# no_train=[]\n",
        "# no_test=[]\n",
        "# val_train=[]\n",
        "# val_test=[]\n",
        "\n",
        "# for i in range(len(test_pos_imgs)):\n",
        "#     try:\n",
        "#         yes_train.append(crop_image(test_pos_imgs[i]))\n",
        "#         yes_test.append(crop_image2(test_pos_imgs[i]))\n",
        "#     except:\n",
        "#         pass\n",
        "    \n",
        "    \n",
        "# for i in range(len(test_neg_imgs)):\n",
        "#     try:\n",
        "#         no_train.append(crop_image(test_neg_imgs[i]))\n",
        "#         no_test.append(crop_image2(test_neg_imgs[i]))\n",
        "#     except:\n",
        "#         pass\n",
        "\n",
        "# for i in range(len(val_neg_imgs)):\n",
        "#     try:\n",
        "#         val_train.append(crop_image(test_neg_imgs[i]))\n",
        "#         val_test.append(crop_image2(test_neg_imgs[i]))\n",
        "#     except:\n",
        "#         pass"
      ],
      "metadata": {
        "id": "BltBsRZY-Ttg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGiSB773-TrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzp6OJxP-Tms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_tsmYSCG-Tj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_kVXFXlt-TTn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}